{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REfGOWUaA_J2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from PIL import Image\n",
        "from torchvision.io import read_image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1PQSlGXGmN1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHxcmewczbJ_",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!unzip images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXV_H1UjbX1l",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!rm -rf images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xSPYVxDzFye",
        "tags": []
      },
      "outputs": [],
      "source": [
        "img = read_image('./images/1.jpg')\n",
        "print(img[:,:,:512].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY-Qv0IsBOWK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#U-Net, Generator\n",
        "\n",
        "class Genearator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def initial(in_channel, out_channel, kernel, stride):\n",
        "          layers = [\n",
        "              nn.Conv2d(in_channel, out_channel, kernel_size=kernel, stride=stride, padding=1),\n",
        "              nn.LeakyReLU(0.2)\n",
        "          ]\n",
        "          return nn.Sequential(*layers)\n",
        "\n",
        "        def encode(in_channel, out_channel, kernel, stride, padding):\n",
        "          layers = [\n",
        "              nn.Conv2d(in_channel, out_channel, kernel_size=kernel, stride=stride, padding=padding),\n",
        "              nn.BatchNorm2d(out_channel),\n",
        "              nn.LeakyReLU(0.2)\n",
        "          ]\n",
        "          return nn.Sequential(*layers)\n",
        "\n",
        "        def decode(in_channel, out_channel, kernel, stride):\n",
        "          layers = [\n",
        "              nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel, stride=stride, padding=1),\n",
        "              nn.BatchNorm2d(out_channel),\n",
        "              nn.ReLU(),\n",
        "              nn.Dropout(0.5)\n",
        "          ]\n",
        "          return nn.Sequential(*layers)\n",
        "\n",
        "        def final(in_channel, out_channel):\n",
        "          layers = [\n",
        "                nn.ConvTranspose2d(in_channel, out_channel, kernel_size=1, stride=1),\n",
        "                nn.Tanh()\n",
        "          ]\n",
        "          return  nn.Sequential(*layers)\n",
        "\n",
        "        self.encode1 = initial(3, 64, 4, 2) #256\n",
        "        self.encode2 = encode(64, 128, 4, 2, 1) #128\n",
        "        self.encode3 = encode(128, 256, 4, 2, 1) #64\n",
        "        self.encode4 = encode(256, 256, 4, 2, 1) #32\n",
        "        self.encode5 = encode(256, 256, 4, 2, 1) #16\n",
        "\n",
        "        self.bottleneck = encode(256, 256, 1, 1, 0) #16\n",
        "        self.decode1 = decode(256+256, 256, 4, 2) #32\n",
        "        self.decode2 = decode(256+256, 256, 4, 2) #64\n",
        "        self.decode3 = decode(256+256, 128, 4, 2) #128\n",
        "        self.decode4 = decode(128+128, 64, 4, 2) #256\n",
        "        self.decode5 = decode(64+64, 3, 4, 2) #512\n",
        "\n",
        "        self.final = final(3+3, 3) #512\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        source_image = x.view(-1, 3, 512, 512)\n",
        "        encode1 = self.encode1(source_image)\n",
        "        encode2 = self.encode2(encode1)\n",
        "        encode3 = self.encode3(encode2)\n",
        "        encode4 = self.encode4(encode3)\n",
        "        encode5 = self.encode5(encode4)\n",
        "\n",
        "        bottleneck = self.bottleneck(encode5) #(1, 512, 16, 16)\n",
        "        #print(\"BN\", bottleneck.shape)\n",
        "\n",
        "        decode1 = self.decode1(torch.cat((bottleneck, encode5), dim=1))\n",
        "        decode2 = self.decode2(torch.cat((decode1, encode4), dim=1))\n",
        "        decode3 = self.decode3(torch.cat((decode2, encode3), dim=1))\n",
        "        decode4 = self.decode4(torch.cat((decode3, encode2), dim=1))\n",
        "        decode5 = self.decode5(torch.cat((decode4, encode1), dim=1))\n",
        "\n",
        "        final_layer = self.final(torch.cat((decode5, source_image), dim=1))\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AER4bVNpHbA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# PatchGAN discriminator\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dis_seq = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(6, 64, 4, 2, padding=1, padding_mode=\"reflect\"), #256\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, padding=1, padding_mode=\"reflect\"), # 128\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, padding=1, padding_mode=\"reflect\"), # 64\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            nn.Conv2d(256, 1, 4, 1, padding=1, padding_mode=\"reflect\"), # 63\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.view(-1, 6, 512, 512)\n",
        "        x = self.dis_seq(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWgtaC67EPih",
        "tags": []
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator()\n",
        "discriminator = discriminator.to(device)\n",
        "generator = Genearator()\n",
        "generator = generator.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO_BXIuOcv3c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "generator.load_state_dict(torch.load('generator.pt', weights_only=True, map_location='cpu'))\n",
        "discriminator.load_state_dict(torch.load('discriminator.pt', weights_only=True, map_location='cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P1sdkx9z3mF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#DataLoader\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = (read_image(img_path)/255).float()\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "images_dataset = ImageDataset(img_dir = 'images',\n",
        "                             annotations_file = 'labels.csv',\n",
        "                             transform = transform)\n",
        "images_dl = DataLoader(images_dataset, batch_size=batch_size)\n",
        "\n",
        "total_images = len(images_dataset)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl4CC7rEu4xw",
        "tags": []
      },
      "outputs": [],
      "source": [
        "epochs = 10000\n",
        "lr = 0.0002\n",
        "batch_size = 16\n",
        "l1_var = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnnatLSMzKus",
        "tags": []
      },
      "outputs": [],
      "source": [
        "loss_bce = nn.BCEWithLogitsLoss()\n",
        "loss_l1 = nn.L1Loss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_and_show_result_val = 20\n",
        "def show_result():\n",
        "    rand_str = str(random.randint(1, total_images))\n",
        "\n",
        "    test_src_image = (read_image('./images/'+rand_str+'.jpg')[:,:,:512]/255).float()\n",
        "    test_src_image = transform(test_src_image).to(device)\n",
        "\n",
        "    test_target_image = (read_image('./images/'+rand_str+'.jpg')[:,:,512:]/255).float()\n",
        "    test_target_image = transform(test_target_image).to(device)\n",
        "\n",
        "    generator_eval = generator.eval()\n",
        "    gen_img = generator_eval(test_src_image)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axs[0].imshow(test_src_image.cpu().permute(1, 2, 0))\n",
        "    axs[0].set_title(\"Source(\"+rand_str+\".jpg)\")\n",
        "\n",
        "    axs[1].imshow(gen_img.detach().cpu().squeeze().permute(1, 2, 0))\n",
        "    axs[1].set_title(\"Generated\")\n",
        "\n",
        "    axs[2].imshow(test_target_image.cpu().permute(1, 2, 0))\n",
        "    axs[2].set_title(\"Target\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def show_result_single(img):\n",
        "    src_img = (read_image(img)/255).float()\n",
        "    src_img = transform(src_img).to(device)\n",
        "\n",
        "    generator_eval = generator.eval()\n",
        "    gen_img = generator_eval(src_img)\n",
        "\n",
        "    plt.imshow(gen_img.detach().cpu().squeeze().permute(1, 2, 0))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dYTcYK9K95mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j408T-jlzl5c",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for img, label in images_dl:\n",
        "\n",
        "    img = img.to(device)\n",
        "\n",
        "    src_img = img[:, :, :, :512]\n",
        "    tgt_img = img[:, :, :, 512:]\n",
        "\n",
        "    gen_img = generator(src_img)\n",
        "\n",
        "    # Generator\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    srcGenCat_gen = torch.cat((src_img, gen_img), dim=1)\n",
        "    dis_call_gen = discriminator(srcGenCat_gen).detach().squeeze()\n",
        "    G_adv_loss = loss_bce(dis_call_gen, torch.ones_like(dis_call_gen).to(device))\n",
        "    G_l1_loss = loss_l1(gen_img, tgt_img)\n",
        "    loss_G = G_adv_loss + l1_var * G_l1_loss\n",
        "    loss_G.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "\n",
        "    # Discriminator\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    srcTgtCat = torch.cat((src_img, tgt_img), dim=1)\n",
        "    srcGenCat = torch.cat((src_img, gen_img.detach()), dim=1)\n",
        "    dis_call = discriminator(srcTgtCat).squeeze()\n",
        "    real_loss = loss_bce(dis_call, torch.ones_like(dis_call).to(device))\n",
        "    dis_call = discriminator(srcGenCat).squeeze()\n",
        "    fake_loss = loss_bce(dis_call, torch.zeros_like(dis_call).to(device))\n",
        "    loss_D = (fake_loss+real_loss)/2\n",
        "    loss_D.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "\n",
        "  if ((epoch+1)%1) == 0:\n",
        "\n",
        "    gen_loss = loss_G.item()\n",
        "    dis_loss = loss_D.item()\n",
        "    #print(f\"Epoch{epoch+1} Discriminator Loss: {dis_loss}, Generator Loss: {gen_loss}\", end='\\r')\n",
        "    print(f\"Epoch{epoch+1} Discriminator Loss: {dis_loss}, Generator Loss: {gen_loss}\")\n",
        "\n",
        "  if ((epoch+1)%save_and_show_result_val) == 0:\n",
        "\n",
        "      torch.save(generator.state_dict(), 'generator.pt')\n",
        "      torch.save(discriminator.state_dict(), 'discriminator.pt')\n",
        "\n",
        "      show_result()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_result()"
      ],
      "metadata": {
        "id": "e3P5hQ1YXrKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_result_single('test.jpg')"
      ],
      "metadata": {
        "id": "MeogYxpaEoPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy"
      ],
      "metadata": {
        "id": "_0uELRYBG1G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "id": "5vwpIh-1CkEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randn(3, 512, 512).to(device)\n",
        "out = generator(img)\n",
        "torch.onnx.export(generator.eval(), out, \"generator.onnx\", input_names=['input'])"
      ],
      "metadata": {
        "id": "G6GJoIvv_osx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6007036,
          "sourceId": 9803868,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "sagemaker-distribution:Python",
      "language": "python",
      "name": "conda-env-sagemaker-distribution-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}